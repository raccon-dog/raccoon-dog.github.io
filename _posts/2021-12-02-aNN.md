---
layout : single
title : "인공 뉴런을 이용한 딥러닝 -colab"
categories: Coding_Class
tag : [Python,DeepLearning,Colab]
author_profile: false
toc : true
toc_sticky: true
sidebar:
    nav: "docs"
---
# Neural Networks and Deep Learning


```python
# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
%matplotlib inline
```


```python
from google.colab import drive
drive.mount('/content/drive')
```

    Mounted at /content/drive
    


```python
import os
```


```python
os.chdir('/content/drive/MyDrive/python/day16 (1)')
```


```python
df = pd.read_csv('Churn_Modelling.csv')
```


```python
# 1. 비어 있는 데이터 확인
df.isna().sum()
```




    RowNumber          0
    CustomerId         0
    Surname            0
    CreditScore        0
    Geography          0
    Gender             0
    Age                0
    Tenure             0
    Balance            0
    NumOfProducts      0
    HasCrCard          0
    IsActiveMember     0
    EstimatedSalary    0
    Exited             0
    dtype: int64




```python
# 2. X와 y설정
```


```python
df.head(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>RowNumber</th>
      <th>CustomerId</th>
      <th>Surname</th>
      <th>CreditScore</th>
      <th>Geography</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Tenure</th>
      <th>Balance</th>
      <th>NumOfProducts</th>
      <th>HasCrCard</th>
      <th>IsActiveMember</th>
      <th>EstimatedSalary</th>
      <th>Exited</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>15634602</td>
      <td>Hargrave</td>
      <td>619</td>
      <td>France</td>
      <td>Female</td>
      <td>42</td>
      <td>2</td>
      <td>0.00</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>101348.88</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>15647311</td>
      <td>Hill</td>
      <td>608</td>
      <td>Spain</td>
      <td>Female</td>
      <td>41</td>
      <td>1</td>
      <td>83807.86</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>112542.58</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
X=df.iloc[:,3:-1]
```


```python
y= df['Exited']
```


```python
# 3. 문자열 데이터를 인코딩
```


```python
# X의 Geography 컬럼은 3개 => 원 핫 인코딩
# Gender 컬럼은 2개 => 레이블 인코딩
```


```python
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
```


```python
X = pd.get_dummies(X,columns=['Geography'])
```


```python
encoder = LabelEncoder()
```


```python
# Female , Male 정렬하면 , Female 이 0 , male 이 1이 된다.
X['Gender']= encoder.fit_transform(X['Gender'])
```


```python
X.drop('Geography_France',axis=1,inplace=True)
```


```python
X.head(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CreditScore</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Tenure</th>
      <th>Balance</th>
      <th>NumOfProducts</th>
      <th>HasCrCard</th>
      <th>IsActiveMember</th>
      <th>EstimatedSalary</th>
      <th>Geography_Germany</th>
      <th>Geography_Spain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>619</td>
      <td>0</td>
      <td>42</td>
      <td>2</td>
      <td>0.00</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>101348.88</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>608</td>
      <td>0</td>
      <td>41</td>
      <td>1</td>
      <td>83807.86</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>112542.58</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 원 핫 인코딩한 결과의 맨 왼쪽 컬럼은, 삭제를 해도, 0과 1로 모두 3개 데이터 표현가능.
# Dummy varialbe trap : 즉 맨 왼쪽 하나의 컬럼은 지워도 된다. 
# 0 0 1 => 0 1
# 0 1 0 => 1 0
# 1 0 0 => 0 0
```


```python
# 4. 각 데이터의 범위를 일정하게 맞춰주는, 피쳐 스케일링 한다.
#    딥러닝의 경우 필수.
```


```python
from sklearn.preprocessing import MinMaxScaler
```


```python
scaler = MinMaxScaler()
```


```python
X = scaler.fit_transform(X)
```


```python
# 5. 학습용 데이터와 테스용으로 나눈다.
```


```python
from sklearn.model_selection import train_test_split
```


```python
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.2,random_state=0)
```


```python
# 6. 모델링
```


```python
import tensorflow as tf
```


```python
from tensorflow.keras.models import Sequential
```


```python
from tensorflow.keras.layers import Dense
```


```python
model = Sequential()
```


```python
X.shape
```




    (10000, 11)




```python
# 첫번째 히든 레이어 생성 , 이 때는 인풋 레이어의 숫자도 세팅해준다.
# 인풋 디멘션의 숫자는 X의 컬럼의 수와 동일하다. 
model.add( Dense(units=6,activation='relu',input_dim=11) )
```


```python
# 두번째 히든 레이어 구성.
model.add( Dense(units=8,activation='relu'))
```


```python
# 아웃풋 레이어 생성.
model.add(Dense(units=1,activation='sigmoid'))
```


```python
# compile(컴파일) 한다.
# 오차함수를 설정하고, 옵티마이저(그레디언트 디센트 알고리즘) 를 설정한다.
```


```python
# 옵티미이저는 , 그레디언트 디센트 알고리즘을 개선한 것들 중에서 선택하면 된다.
# 그레디언트 디센트는 오차가 최소가 될때의 W값을 찾는 알고리즘이다.

# loss 는 오차함수를 말한다.
# 분류의 문제는 2가지로 나뉜다. 
# 1. 2개로 분류 하는 방법 : binary_crossentropy
# 2. 3개 이상으로 분류하는 문제 : categorical_crossentropy
# 위의 2개 중에 하나를 설정해 준다.

# metrics 분류의 문제는 보통 정확도를 측정한다. 따라서 accuracy 를 설정해준다.

model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])
```


```python
# 만든 모델을 요약
model.summary()
```

    Model: "sequential_2"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     dense_6 (Dense)             (None, 6)                 72        
                                                                     
     dense_7 (Dense)             (None, 8)                 56        
                                                                     
     dense_8 (Dense)             (None, 1)                 9         
                                                                     
    =================================================================
    Total params: 137
    Trainable params: 137
    Non-trainable params: 0
    _________________________________________________________________
    


```python
# compile 이 끝나면 , 학습한다.

# 학습할때, 파라미터를 2개만 셋팅했을때
# model.fit(X_train,y_train)
# 250/250 [==============================] - 2s 2ms/step - loss: 0.5547 - accuracy: 0.7705
# <keras.callbacks.History at 0x7f06817caf90>
```

    250/250 [==============================] - 2s 2ms/step - loss: 0.5547 - accuracy: 0.7705
    




    <keras.callbacks.History at 0x7f06817caf90>




```python
model.fit(X_train,y_train, epochs=20,batch_size=10)
```

    Epoch 1/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4266 - accuracy: 0.8133
    Epoch 2/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4248 - accuracy: 0.8158
    Epoch 3/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4231 - accuracy: 0.8171
    Epoch 4/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4214 - accuracy: 0.8175
    Epoch 5/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4216 - accuracy: 0.8192
    Epoch 6/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4193 - accuracy: 0.8220
    Epoch 7/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4188 - accuracy: 0.8221
    Epoch 8/20
    800/800 [==============================] - 1s 2ms/step - loss: 0.4178 - accuracy: 0.8226
    Epoch 9/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4170 - accuracy: 0.8240
    Epoch 10/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4156 - accuracy: 0.8263
    Epoch 11/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4145 - accuracy: 0.8270
    Epoch 12/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4133 - accuracy: 0.8266
    Epoch 13/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4135 - accuracy: 0.8294
    Epoch 14/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4115 - accuracy: 0.8288
    Epoch 15/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4116 - accuracy: 0.8282
    Epoch 16/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4107 - accuracy: 0.8301
    Epoch 17/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4103 - accuracy: 0.8299
    Epoch 18/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4093 - accuracy: 0.8314
    Epoch 19/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4093 - accuracy: 0.8319
    Epoch 20/20
    800/800 [==============================] - 2s 2ms/step - loss: 0.4081 - accuracy: 0.8319
    




    <keras.callbacks.History at 0x7f0681586b50>




```python
# 학습이 끝나면, 평가해야 한다.
```


```python
y_pred = model.predict(X_test)
```


```python
# 0 - 1 사이의 값이 나온다.
# 이유는? 아웃풋 레이어의 액티베이션 펑션으로 시그모이드 함수를 사용했기 때문에

y_pred
```




    array([[0.18764818],
           [0.35891125],
           [0.19544896],
           ...,
           [0.16212165],
           [0.10967347],
           [0.21831426]], dtype=float32)




```python
# y_pred 값이, 실수로 나왔기 때문에, 컨퓨전 매트릭스에 넣을 수가 없다.
# 따라서 0.5를 기준으로, 크면 1로, 작으면 0으로 맞춰줘야 한다.

y_pred = (y_pred>0.5).astype(int)
```


```python
# y_pred 는 2차원이므로, 컨퓨전 매트릭스에 넣을 수 없기 때문에
# 1차원으로 만들어 준다.
y_pred = y_pred.reshape(2000,)
```


```python
from sklearn.metrics import confusion_matrix, accuracy_score
```


```python
confusion_matrix(y_test,y_pred)
```




    array([[1549,   46],
           [ 280,  125]])




```python
accuracy_score(y_test,y_pred)
```




    0.837




```python
# 텐서플로우의 평가 함수 제공.

model.evaluate(X_test,y_test)
```

    63/63 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.8370
    




    [0.40435704588890076, 0.8370000123977661]



## 다음 신규 데이터를 통해 분류해 보자

- Geography: France
- Credit Score: 600
- Gender: Male
- Age: 40
- Tenure: 3
- Balance: 60000
- Number of Products: 2
- Has Credit Card: Yes
- Is Active Member: Yes
- Estimated Salary: 50000


```python
# 더미 베리어블 트랩 해결.
```


```python
A = np.array([600,1,42,3,60000,2,1,1,50000,0,0])
```


```python
A = A.reshape(1,11)
```


```python
A = scaler.transform(A)
```


```python
model.predict(A)
```




    array([[0.]], dtype=float32)



### 용어 정리

epoch

- 한 번의 epoch는 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것을 말함. 즉, 전체 데이터 셋에 대해 한 번 학습을 완료한 상태


batch_size

메모리의 한계와 속도 저하 때문에 대부분의 경우에는 한 번의 epoch에서 모든 데이터를 한꺼번에 집어넣을 수는 없습니다. 그래서 데이터를 나누어서 주게 되는데 이때 몇 번 나누어서 주는가를 iteration, 각 iteration마다 주는 데이터 사이즈를 batch size라고 합니다.

출처: https://www.slideshare.net/w0ong/ss-82372826


