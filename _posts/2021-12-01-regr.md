---
layout : single
title : "Logistic-Regression 실습-colab"
categories: Coding_Training
tag : [Python,MachineLearning,Colab]
author_profile: false
toc : true
toc_sticky: true
sidebar:
    nav: "docs"
---
# 자동차 구매 가격 예측



# PROBLEM STATEMENT

다음과 같은 컬럼을 가지고 있는 데이터셋을 읽어서, 어떠한 고객이 있을때, 그 고객이 얼마정도의 차를 구매할 수 있을지를 예측하여, 그 사람에게 맞는 자동차를 보여주려 한다. 

- Customer Name
- Customer e-mail
- Country
- Gender
- Age
- Annual Salary 
- Credit Card Debt 
- Net Worth (순자산)

예측하고자 하는 값 : 
- Car Purchase Amount 

# STEP #0: 라이브러리 임포트 및 코랩 환경 설정

[구글 드라이브 파일 읽기 참고](https://vision-ai.tistory.com/entry/%EC%BD%94%EB%9E%A9%EC%97%90%EC%84%9C-%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C%EC%9D%98-csv-%ED%8C%8C%EC%9D%BC-%EC%9D%BD%EA%B8%B0)



```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```

### csv 파일을 읽기 위해, 구글 드라이브 마운트 하시오


```python
from google.colab import drive
drive.mount('/content/drive')
```

    Mounted at /content/drive
    

### working directory 를, 현재의 파일이 속한 폴더로 셋팅하시오.


```python
import os
```


```python
os.chdir('/content/drive/MyDrive/python/day14')
```


```python

```

# STEP #1: IMPORT DATASET

### Car_Purchasing_Data.csv 파일을 사용한다.  코랩의 경우 구글드라이브의 전체경로를 복사하여 파일 읽는다. 

### 인코딩은 다음처럼 한다. encoding='ISO-8859-1'


```python
pd.read_csv('Car_Purchasing_Data.csv', encoding='ISO-8859-1')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Customer Name</th>
      <th>Customer e-mail</th>
      <th>Country</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Annual Salary</th>
      <th>Credit Card Debt</th>
      <th>Net Worth</th>
      <th>Car Purchase Amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Martina Avila</td>
      <td>cubilia.Curae.Phasellus@quisaccumsanconvallis.edu</td>
      <td>Bulgaria</td>
      <td>0</td>
      <td>41.851720</td>
      <td>62812.09301</td>
      <td>11609.380910</td>
      <td>238961.2505</td>
      <td>35321.45877</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Harlan Barnes</td>
      <td>eu.dolor@diam.co.uk</td>
      <td>Belize</td>
      <td>0</td>
      <td>40.870623</td>
      <td>66646.89292</td>
      <td>9572.957136</td>
      <td>530973.9078</td>
      <td>45115.52566</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Naomi Rodriquez</td>
      <td>vulputate.mauris.sagittis@ametconsectetueradip...</td>
      <td>Algeria</td>
      <td>1</td>
      <td>43.152897</td>
      <td>53798.55112</td>
      <td>11160.355060</td>
      <td>638467.1773</td>
      <td>42925.70921</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jade Cunningham</td>
      <td>malesuada@dignissim.com</td>
      <td>Cook Islands</td>
      <td>1</td>
      <td>58.271369</td>
      <td>79370.03798</td>
      <td>14426.164850</td>
      <td>548599.0524</td>
      <td>67422.36313</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cedric Leach</td>
      <td>felis.ullamcorper.viverra@egetmollislectus.net</td>
      <td>Brazil</td>
      <td>1</td>
      <td>57.313749</td>
      <td>59729.15130</td>
      <td>5358.712177</td>
      <td>560304.0671</td>
      <td>55915.46248</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>495</th>
      <td>Walter</td>
      <td>ligula@Cumsociis.ca</td>
      <td>Nepal</td>
      <td>0</td>
      <td>41.462515</td>
      <td>71942.40291</td>
      <td>6995.902524</td>
      <td>541670.1016</td>
      <td>48901.44342</td>
    </tr>
    <tr>
      <th>496</th>
      <td>Vanna</td>
      <td>Cum.sociis.natoque@Sedmolestie.edu</td>
      <td>Zimbabwe</td>
      <td>1</td>
      <td>37.642000</td>
      <td>56039.49793</td>
      <td>12301.456790</td>
      <td>360419.0988</td>
      <td>31491.41457</td>
    </tr>
    <tr>
      <th>497</th>
      <td>Pearl</td>
      <td>penatibus.et@massanonante.com</td>
      <td>Philippines</td>
      <td>1</td>
      <td>53.943497</td>
      <td>68888.77805</td>
      <td>10611.606860</td>
      <td>764531.3203</td>
      <td>64147.28888</td>
    </tr>
    <tr>
      <th>498</th>
      <td>Nell</td>
      <td>Quisque.varius@arcuVivamussit.net</td>
      <td>Botswana</td>
      <td>1</td>
      <td>59.160509</td>
      <td>49811.99062</td>
      <td>14013.034510</td>
      <td>337826.6382</td>
      <td>45442.15353</td>
    </tr>
    <tr>
      <th>499</th>
      <td>Marla</td>
      <td>Camaron.marla@hotmail.com</td>
      <td>marlal</td>
      <td>1</td>
      <td>46.731152</td>
      <td>61370.67766</td>
      <td>9391.341628</td>
      <td>462946.4924</td>
      <td>45107.22566</td>
    </tr>
  </tbody>
</table>
<p>500 rows × 9 columns</p>
</div>




```python
car_df = pd.read_csv('Car_Purchasing_Data.csv', encoding='ISO-8859-1')

```

### 컬럼을 확인하고

### 기본 통계 데이터를 확인해 보자


```python
car_df.isna().sum()
```




    Customer Name          0
    Customer e-mail        0
    Country                0
    Gender                 0
    Age                    0
    Annual Salary          0
    Credit Card Debt       0
    Net Worth              0
    Car Purchase Amount    0
    dtype: int64




```python
car_df['Country'].describe()
```




    count        500
    unique       211
    top       Israel
    freq           6
    Name: Country, dtype: object



### 연봉이 가장 높은 사람은 누구인가


```python
car_df[car_df['Annual Salary'] == car_df['Annual Salary'].max() ].loc[:,'Customer Name']
```




    28    Gemma Hendrix
    Name: Customer Name, dtype: object



### 나이가 가장 어린 고객은, 연봉이 얼마인가


```python
car_df[car_df['Age']==car_df['Age'].min()].loc[:,'Annual Salary']
```




    444    70467.29492
    Name: Annual Salary, dtype: float64



# STEP #2: VISUALIZE DATASET

### 상관관계를 분석하기 위해, pairplot 을 그려보자.


```python
sns.pairplot(data = car_df)
plt.show()
```


    
![png](output_22_0.png)
    



```python
cc = car_df.corr()
cc
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Age</th>
      <th>Annual Salary</th>
      <th>Credit Card Debt</th>
      <th>Net Worth</th>
      <th>Car Purchase Amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Gender</th>
      <td>1.000000</td>
      <td>-0.064481</td>
      <td>-0.036499</td>
      <td>0.024193</td>
      <td>-0.008395</td>
      <td>-0.066408</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>-0.064481</td>
      <td>1.000000</td>
      <td>0.000130</td>
      <td>0.034721</td>
      <td>0.020356</td>
      <td>0.632865</td>
    </tr>
    <tr>
      <th>Annual Salary</th>
      <td>-0.036499</td>
      <td>0.000130</td>
      <td>1.000000</td>
      <td>0.049599</td>
      <td>0.014767</td>
      <td>0.617862</td>
    </tr>
    <tr>
      <th>Credit Card Debt</th>
      <td>0.024193</td>
      <td>0.034721</td>
      <td>0.049599</td>
      <td>1.000000</td>
      <td>-0.049378</td>
      <td>0.028882</td>
    </tr>
    <tr>
      <th>Net Worth</th>
      <td>-0.008395</td>
      <td>0.020356</td>
      <td>0.014767</td>
      <td>-0.049378</td>
      <td>1.000000</td>
      <td>0.488580</td>
    </tr>
    <tr>
      <th>Car Purchase Amount</th>
      <td>-0.066408</td>
      <td>0.632865</td>
      <td>0.617862</td>
      <td>0.028882</td>
      <td>0.488580</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
sns.heatmap(data = cc,annot=True,vmin=-1,vmax=1,cmap='coolwarm',linewidths= 0.5 , square=True)
plt.show()
```


    
![png](output_24_0.png)
    


# STEP #3: CREATE TESTING AND TRAINING DATASET/DATA CLEANING




### NaN 값이 있으면, 이를 해결하시오.


```python
car_df.isna().sum()
```




    Customer Name          0
    Customer e-mail        0
    Country                0
    Gender                 0
    Age                    0
    Annual Salary          0
    Credit Card Debt       0
    Net Worth              0
    Car Purchase Amount    0
    dtype: int64



### 학습을 위해 'Customer Name', 'Customer e-mail', 'Country', 'Car Purchase Amount' 컬럼을 제외한 컬럼만, X로 만드시오.


```python
X = car_df.loc[:,'Gender':'Net Worth']
```


```python
X.shape
```




    (500, 5)



### y 값은 'Car Purchase Amount' 컬럼으로 셋팅하시오.


```python
y = car_df['Car Purchase Amount']
```

### 피처 스케일링 하겠습니다. 정규화(normalization)를 사용합니다. MinMaxScaler 를 이용하시오.


```python
from sklearn.preprocessing import MinMaxScaler
```


```python
scaler_X = MinMaxScaler()
```


```python
X = scaler_X.fit_transform(X)
```

### 학습을 위해서, y 의 shape 을 변경하시오.


```python
y= car_df.iloc[:,-1]
```


```python
y = y.to_numpy().reshape(500,1)
```


```python
y.shape
```




    (500, 1)



### y 도 피처 스케일링 하겠습니다. X 처럼 y도 노멀라이징 하시오.


```python
scaler_y = MinMaxScaler()
```


```python
y = scaler_y.fit_transform(y)
```

# STEP#4: TRAINING THE MODEL

### 트레이닝셋과 테스트셋으로 분리하시오. (테스트 사이즈는 25%로 하며, 동일 결과를 위해 랜덤스테이트는 50 으로 셋팅하시오.)


```python
from sklearn.model_selection import train_test_split
```


```python
X_train , X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25 ,random_state = 50)
```

## 1. RandomForest 나 XGBoost 를 이용하시오.


```python
from sklearn.ensemble import RandomForestRegressor
```


```python
regressor = RandomForestRegressor(50)
```


```python
regressor.fit(X_train,y_train)
```

    /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
      """Entry point for launching an IPython kernel.
    




    RandomForestRegressor(n_estimators=50)




```python
y_pred = regressor.predict(X_test)
```


```python
# y_test 값이 , 피처 스케일링을 통해서 2차원으로 만들어져 있기 때문에 오차를 구하려면 이를 다시 1차원으로 변경시켜줘야한다.
```


```python
y_test = y_test.reshape(125,)
```


```python
error = y_test - y_pred
```


```python
MSE = (error ** 2).mean()
```


```python
MSE
```




    0.001821193287592156




```python
plt.plot(y_test)
plt.plot(y_pred)
plt.show()
```


    
![png](output_58_0.png)
    



```python
# 유저가 앱을 통해서 데이터를 입력했습니다.
# 이 사람은 얼마 정도의 차를 구매할 수 있는지 예측하세요.

# 여자이고, 나이는 38살, 연봉은 78000달러 카드빚은 15000달러 이고 자산은 480,000 달러입니다.
# 이 사람은 얼마짜리 차를 구매할 여력이 될까요?
```


```python
car_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Customer Name</th>
      <th>Customer e-mail</th>
      <th>Country</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Annual Salary</th>
      <th>Credit Card Debt</th>
      <th>Net Worth</th>
      <th>Car Purchase Amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Martina Avila</td>
      <td>cubilia.Curae.Phasellus@quisaccumsanconvallis.edu</td>
      <td>Bulgaria</td>
      <td>0</td>
      <td>41.851720</td>
      <td>62812.09301</td>
      <td>11609.380910</td>
      <td>238961.2505</td>
      <td>35321.45877</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Harlan Barnes</td>
      <td>eu.dolor@diam.co.uk</td>
      <td>Belize</td>
      <td>0</td>
      <td>40.870623</td>
      <td>66646.89292</td>
      <td>9572.957136</td>
      <td>530973.9078</td>
      <td>45115.52566</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Naomi Rodriquez</td>
      <td>vulputate.mauris.sagittis@ametconsectetueradip...</td>
      <td>Algeria</td>
      <td>1</td>
      <td>43.152897</td>
      <td>53798.55112</td>
      <td>11160.355060</td>
      <td>638467.1773</td>
      <td>42925.70921</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jade Cunningham</td>
      <td>malesuada@dignissim.com</td>
      <td>Cook Islands</td>
      <td>1</td>
      <td>58.271369</td>
      <td>79370.03798</td>
      <td>14426.164850</td>
      <td>548599.0524</td>
      <td>67422.36313</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cedric Leach</td>
      <td>felis.ullamcorper.viverra@egetmollislectus.net</td>
      <td>Brazil</td>
      <td>1</td>
      <td>57.313749</td>
      <td>59729.15130</td>
      <td>5358.712177</td>
      <td>560304.0671</td>
      <td>55915.46248</td>
    </tr>
  </tbody>
</table>
</div>




```python
new_data = np.array([0,38,78000,15000,480000]).reshape(1,5)
```


```python
new_data = scaler_X.transform(new_data)
```

    /usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names
      "X does not have valid feature names, but"
    


```python
# 피쳐 스케일링 해줘야 하는데.
# 학습할떄 사용한 스케일러가 이미 , 최대 최소값들을 가지고 있기 때문에
# 그 스케일러를 이용해서 변환해야한다.
```


```python
y_pred = regressor.predict(new_data)
```


```python
scaler_y.inverse_transform(y_pred.reshape(1,1))
```




    array([[47448.7187924]])


