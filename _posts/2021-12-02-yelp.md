---
layout : single
title : "Naive_Bayes를 이용한 리뷰 분류 -colab"
categories: Coding_Training
tag : [Python,MachineLearning,Colab]
author_profile: false
toc : true
toc_sticky: true
sidebar:
    nav: "docs"
---
# YELP 서비스의 리뷰 분석 (NLP)




# PROBLEM STATEMENT

- stars 컬럼은, 유저가 1점부터 5점까지 준 별점이 들어있다.
- text 컬럼은, 별점을 준 유저의 리뷰가 들어있다. 
- cool, useful, funny 컬럼은, 다른사람들이 이 리뷰 글에 투표한 숫자다. 따라서 쿨이 3개이면, 이 리뷰에 대해서 3명이 쿨에 공감했다는 뜻이다.

# STEP #0: LIBRARIES IMPORT



```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
```


```python
from google.colab import drive
drive.mount('/content/drive')
```

    Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
    


```python
import os
os.chdir('/content/drive/MyDrive/python/day15')
```

# STEP #1: IMPORT DATASET

### yelp.csv 파일을 읽어서, yelp_df 변수에 저장하고, 기본적인 통계 분석을 하시오.


```python
df = pd.read_csv('yelp.csv')
```


```python
df.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>business_id</th>
      <th>date</th>
      <th>review_id</th>
      <th>stars</th>
      <th>text</th>
      <th>type</th>
      <th>user_id</th>
      <th>cool</th>
      <th>useful</th>
      <th>funny</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9yKzy9PApeiPPOUJEtnvkg</td>
      <td>2011-01-26</td>
      <td>fWKvX83p0-ka4JS3dc6E5A</td>
      <td>5</td>
      <td>My wife took me here on my birthday for breakf...</td>
      <td>review</td>
      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>
      <td>2</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ZRJwVLyzEJq1VAihDhYiow</td>
      <td>2011-07-27</td>
      <td>IjZ33sJrzXqU-0X6U8NwyA</td>
      <td>5</td>
      <td>I have no idea why some people give bad review...</td>
      <td>review</td>
      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6oRAC4uyJCsJl1X0WZpVSA</td>
      <td>2012-06-14</td>
      <td>IESLBzqUCLdSzSqm0eCSxQ</td>
      <td>4</td>
      <td>love the gyro plate. Rice is so good and I als...</td>
      <td>review</td>
      <td>0hT2KtfLiobPvh6cDC8JQg</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>
      <td>2010-05-27</td>
      <td>G-WvGaISbqqaMHlNnByodA</td>
      <td>5</td>
      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>
      <td>review</td>
      <td>uZetl9T0NcROGOyFfughhg</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6ozycU1RpktNG2-1BroVtw</td>
      <td>2012-01-05</td>
      <td>1uJFq2r5QfJG_6ExMRCaGw</td>
      <td>5</td>
      <td>General Manager Scott Petello is a good egg!!!...</td>
      <td>review</td>
      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



# STEP #2: VISUALIZE DATASET

### 리뷰 데이터의 길이를 구하여, 새로운 컬럼 length 컬럼을 만드시오


```python
df['length']= df['text'].apply(len)

```

### 리뷰의 length를 히스토그램으로 나타내시오.  


```python
df['length'].hist()
plt.show()
```


    
![png](/images/naive2/output_15_0.png)
    


### 리뷰가 가장 긴 글을 찾아서, 리뷰 내용을 보여주세요.


```python
(df.loc[df['length'] == df['length'].max(),])['text'].values
```

### 리뷰가 가장 짧은 리뷰는 총 몇개이며, 리뷰 내용은 무엇입니까?


```python
(df.loc[df['length'] == df['length'].min(),])['text'].values
```




    array(['X'], dtype=object)



### 별점은 1점부터 5점까지 입니다. 각 별점별로 리뷰가 몇개씩 있는지를 시각화 하시오.


```python
sns.countplot(data = df,x='stars')
plt.show()
```


    
![png](/images/naive2/output_21_0.png)
    


### 별점별로 리뷰가 몇개씩 있는지 시각화 하되, 내림차순으로 정렬하여 시각화 하시오.


```python
my_order = df['stars'].value_counts().index
```


```python
sns.countplot(data = df,x='stars',order=my_order)
plt.show()
```


    
![png](/images/naive2/output_24_0.png)
    


### 별점이 1점인 리뷰의 데이터프레임과, 별점아 5점인 데이터프레임을 각각 따로 아래의 변수에 저장하시오.
### 변수명은 yelp_df_1 , yelp_df_5 로 저장하시오.


```python
yelp_df_1 = df.loc[df['stars'] == 1,]
```


```python
yelp_df_5 = df.loc[df['stars'] == 5,]
```

### yelp_df_1 , yelp_df_5 두개의 데이터프레임을 하나로 합치시오.  긍정과 부정의 리뷰 학습을 위해서 하나로 합치는 것이다.


```python
yelp_df_1_5 = pd.concat([yelp_df_1,yelp_df_5])
```


```python
yelp_df_1_5
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>business_id</th>
      <th>date</th>
      <th>review_id</th>
      <th>stars</th>
      <th>text</th>
      <th>type</th>
      <th>user_id</th>
      <th>cool</th>
      <th>useful</th>
      <th>funny</th>
      <th>length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>23</th>
      <td>IJ0o6b8bJFAbG6MjGfBebQ</td>
      <td>2010-09-05</td>
      <td>Dx9sfFU6Zn0GYOckijom-g</td>
      <td>1</td>
      <td>U can go there n check the car out. If u wanna...</td>
      <td>review</td>
      <td>zRlQEDYd_HKp0VS3hnAffA</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>594</td>
    </tr>
    <tr>
      <th>31</th>
      <td>vvA3fbps4F9nGlAEYKk_sA</td>
      <td>2012-05-04</td>
      <td>S9OVpXat8k5YwWCn6FAgXg</td>
      <td>1</td>
      <td>Disgusting!  Had a Groupon so my daughter and ...</td>
      <td>review</td>
      <td>8AMn6644NmBf96xGO3w6OA</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>361</td>
    </tr>
    <tr>
      <th>35</th>
      <td>o1GIYYZJjM6nM03fQs_uEQ</td>
      <td>2011-11-30</td>
      <td>ApKbwpYJdnhhgP4NbjQw2Q</td>
      <td>1</td>
      <td>I've eaten here many times, but none as bad as...</td>
      <td>review</td>
      <td>iwUN95LIaEr75TZE_JC6bg</td>
      <td>0</td>
      <td>4</td>
      <td>3</td>
      <td>1198</td>
    </tr>
    <tr>
      <th>61</th>
      <td>l4vBbCL9QbGiwLuLKwD_bA</td>
      <td>2011-11-22</td>
      <td>DJVxOfj2Rw9zklC9tU3i1w</td>
      <td>1</td>
      <td>I have always been a fan of Burlington's deals...</td>
      <td>review</td>
      <td>EPROVap0M19Y6_4uf3eCmQ</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>569</td>
    </tr>
    <tr>
      <th>64</th>
      <td>CEswyP-9SsXRNLR9fFGKKw</td>
      <td>2012-05-19</td>
      <td>GXj4PNAi095-q9ynPYH3kg</td>
      <td>1</td>
      <td>Another night meeting friends here.  I have to...</td>
      <td>review</td>
      <td>MjLAe48XNfYlTeFYca5gMw</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>498</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9990</th>
      <td>R8VwdLyvsp9iybNqRvm94g</td>
      <td>2011-10-03</td>
      <td>pcEeHdAJPoFNF23es0kKWg</td>
      <td>5</td>
      <td>Yes I do rock the hipster joints.  I dig this ...</td>
      <td>review</td>
      <td>b92Y3tyWTQQZ5FLifex62Q</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>263</td>
    </tr>
    <tr>
      <th>9991</th>
      <td>WJ5mq4EiWYAA4Vif0xDfdg</td>
      <td>2011-12-05</td>
      <td>EuHX-39FR7tyyG1ElvN1Jw</td>
      <td>5</td>
      <td>Only 4 stars? \n\n(A few notes: The folks that...</td>
      <td>review</td>
      <td>hTau-iNZFwoNsPCaiIUTEA</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>908</td>
    </tr>
    <tr>
      <th>9992</th>
      <td>f96lWMIAUhYIYy9gOktivQ</td>
      <td>2009-03-10</td>
      <td>YF17z7HWlMj6aezZc-pVEw</td>
      <td>5</td>
      <td>I'm not normally one to jump at reviewing a ch...</td>
      <td>review</td>
      <td>W_QXYA7A0IhMrvbckz7eVg</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>1326</td>
    </tr>
    <tr>
      <th>9994</th>
      <td>L3BSpFvxcNf3T_teitgt6A</td>
      <td>2012-03-19</td>
      <td>0nxb1gIGFgk3WbC5zwhKZg</td>
      <td>5</td>
      <td>Let's see...what is there NOT to like about Su...</td>
      <td>review</td>
      <td>OzOZv-Knlw3oz9K5Kh5S6A</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1968</td>
    </tr>
    <tr>
      <th>9999</th>
      <td>pF7uRzygyZsltbmVpjIyvw</td>
      <td>2010-10-16</td>
      <td>vWSmOhg2ID1MNZHaWapGbA</td>
      <td>5</td>
      <td>4-5 locations.. all 4.5 star average.. I think...</td>
      <td>review</td>
      <td>KSBFytcdjPKZgXKQnYQdkA</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>461</td>
    </tr>
  </tbody>
</table>
<p>4086 rows × 11 columns</p>
</div>



### 별점 1과 별점 5의 리뷰는 몇개씩인지, 시각화 하시오.


```python
sns.countplot(data=yelp_df_1_5,x='stars')
plt.show()
```


    
![png](/images/naive2/output_32_0.png)
    


### 별점 1점과 별점 5점의 리뷰의 비율이 나오도록, 파이차트로 시각화 하시오.


```python
yelp_df_1_5['stars'].value_counts()
```




    5    3337
    1     749
    Name: stars, dtype: int64




```python
plt.pie(yelp_df_1_5['stars'].value_counts(),labels=yelp_df_1_5['stars'].value_counts().index,autopct='%.1f')
plt.show()
```


    
![png](/images/naive2/output_35_0.png)
    


# STEP #3: CREATE TESTING AND TRAINING DATASET/DATA CLEANING

# 정리 : 위의 과정을 하나의 함수로 만든다.


```python
import string
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
my_stopwords = stopwords.words('english')

def message_cleaning(sentence) :
  Test_punc_removed = [ char for char in sentence if char not in string.punctuation]
  Test_punc_removed_join = ''.join(Test_punc_removed)
  Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in my_stopwords ]
  return Test_punc_removed_join_clean
```

    [nltk_data] Downloading package stopwords to /root/nltk_data...
    [nltk_data]   Unzipping corpora/stopwords.zip.
    

# COUNT VECTORIZER 에 클리닝 함수를 애널라이저로 적용하여, 단어를 숫자로 바꾼다.


```python
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(analyzer=message_cleaning)
```


```python
X = vectorizer.fit_transform(yelp_df_1_5['text'])

```


```python
X = X.toarray()
```


```python
y = yelp_df_1_5['stars']
```

# STEP#4: 학습용과 테스트용으로 데이터프레임을 나눈다. 테스트용은 20%로 설정한다. 그리고 나이브베이즈 모델링 한다.


```python
from sklearn.model_selection import train_test_split
```


```python
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2 , random_state=15)
```


```python
from sklearn.naive_bayes import MultinomialNB, GaussianNB
```


```python
classirier1 = MultinomialNB()
```


```python
classirier1.fit(X_train,y_train)
```




    MultinomialNB()




```python
y_pred = classirier1.predict(X_test)
```


```python
classirier2 = GaussianNB()
```


```python
classirier2.fit(X_train,y_train)
```




    GaussianNB()




```python
y_pred_G = classirier2.predict(X_test)
```

# STEP#5: 테스트셋으로 모델 평가. 컨퓨전 매트릭스 사용한다.


```python
from sklearn.metrics import confusion_matrix, accuracy_score
```


```python
confusion_matrix(y_test,y_pred)
```




    array([[111,  52],
           [ 17, 638]])




```python
accuracy_score(y_test,y_pred)
```




    0.9156479217603912




```python
confusion_matrix(y_test,y_pred_G)
```




    array([[ 54, 109],
           [ 82, 573]])




```python
accuracy_score(y_test,y_pred_G)
```




    0.7665036674816625



# STEP#6 다음 문장이 긍정인지 부정인지 예측하시오.


### 1. 'amazing food! highly recommmended'
### 2. 'shit food, made me sick'


```python
test = vectorizer.transform([ 'amazing food! highly recommmended','shit food, made me sick'])
```


```python
test = test.toarray()
```


```python
classirier1.predict(test)
```




    array([5, 1])


